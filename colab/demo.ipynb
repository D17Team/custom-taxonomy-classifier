{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5iuge2lq3CoI"
      },
      "source": [
        "## Keyword Similarity Demo\n",
        "\n",
        "0. [BASELINE] Get data and get baseline using Fuzzy Match!\n",
        "1. Load USE, BERT and PALM\n",
        "2. Get embeddings from each LM for the taxonomy and store\n",
        "3. [EMBEDDING MATCH] Input Keyword and output closest matches from the taxonomy\n",
        "4. Compare the embedding based keyword category matching with fuzzy matching\n",
        "5. Input Keyword List (file) and output closest matches for each"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xSVDwQBIzwTu"
      },
      "source": [
        "### Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yPdVRW1fzzml"
      },
      "outputs": [],
      "source": [
        "!pip install fuzzywuzzy\n",
        "!pip install tensorflow-text\n",
        "!pip install -U google-generativeai"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rGG6_Rscr1K-"
      },
      "source": [
        "### Utility Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5nEJDii5r3va"
      },
      "outputs": [],
      "source": [
        "def get_overlap_score(df, compare_category_col):\n",
        "  return (df[df['category'] == df[compare_category_col]].shape[0]*100)/df.shape[0]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YE8y05pp7Hnj"
      },
      "source": [
        "### Prepare Data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2YORxMUL5SEp"
      },
      "outputs": [],
      "source": [
        "# prompt: Read data from a csv file stored in google drive\n",
        "import pickle\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xx6KBxGdDP7W"
      },
      "outputs": [],
      "source": [
        "ls drive/MyDrive/1_gPS_Ads/Projects/S1_Classifier/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9wd-6xRwdewa"
      },
      "source": [
        "#### EDU data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iIAeMkvy5iSh"
      },
      "outputs": [],
      "source": [
        "# Read the CSV file\n",
        "import pandas as pd\n",
        "data = pd.read_csv('drive/MyDrive/1_gPS_Ads/Projects/S1_Classifier/s1_tech_keyword_category.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vSupwVfkdJau"
      },
      "outputs": [],
      "source": [
        "data['campaign_name_clean'] = data.campaign_name.apply(lambda x: x.replace('_', ' '))\n",
        "data['ad_group_name_clean'] = data.ad_group_name.apply(lambda x: x.replace('-', ' '))\n",
        "data['ad_group_name_clean'] = data.ad_group_name_clean.apply(lambda x: ' '.join(x.split()))\n",
        "data['keyword_text'] = data['AdGroupCriterion_keyword_text']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9xZRJhCZdKhV"
      },
      "outputs": [],
      "source": [
        "data_subset = data[['campaign_name_clean', 'ad_group_name_clean', 'keyword_text']]\n",
        "data_subset.columns = ['level1', 'category', 'keyword']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IZBWte7VdNkf"
      },
      "outputs": [],
      "source": [
        "data_subset[data_subset.level1 == 'Online School']\n",
        "\n",
        "# Only process for non-online schools since these are not well classified.\n",
        "data_subset = data_subset[(data_subset.level1 != 'Online School') \u0026\n",
        "                          (data_subset.level1 != 'Online Course')]\n",
        "data_subset = data_subset.sample(600, random_state=1).copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WwrZRAgv64V8"
      },
      "source": [
        "#### TECH data processing"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G8UWoMn-66XA"
      },
      "outputs": [],
      "source": [
        "data.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FWEM037y7cmH"
      },
      "outputs": [],
      "source": [
        "data_subset = data.copy()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dAkG71SzmP-g"
      },
      "source": [
        "OOM, use sample"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1UzSJbPWmJNo"
      },
      "outputs": [],
      "source": [
        "data_subset = data_subset.sample(600, random_state=1).copy()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vjcXet6lMww5"
      },
      "outputs": [],
      "source": [
        "set(data.category) - set(data_subset.category)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "suipMURrIQ19"
      },
      "source": [
        "### Keyword Overlap Baseline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "O2z3nhaOIVfE"
      },
      "outputs": [],
      "source": [
        "from fuzzywuzzy import fuzz"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GJQxFalROWtH"
      },
      "outputs": [],
      "source": [
        "category = data_subset.category.unique()\n",
        "keywords = data_subset.keyword.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Ei_f3dLPRPY"
      },
      "outputs": [],
      "source": [
        "fuzz.partial_token_sort_ratio(category[0], keywords[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_VsQ66ABlrXR"
      },
      "outputs": [],
      "source": [
        "data_subset.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eJGDYVdGlud2"
      },
      "outputs": [],
      "source": [
        "category_list = data_subset.category.to_list()\n",
        "keyword_list = data_subset.keyword.to_list()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZYOKIWtbmBa1"
      },
      "outputs": [],
      "source": [
        "import tqdm\n",
        "tsr_scores_dict = {}\n",
        "ptsr_scores_dict = {}\n",
        "fuzzy_score = {}\n",
        "\n",
        "for i, keyword in enumerate((keyword_list)):\n",
        "  for j, category in enumerate(category_list):\n",
        "    #print(keyword, \"|\", category, \":\", fuzz.token_sort_ratio(keyword, category))\n",
        "\n",
        "    tsr_scores_dict[category] = fuzz.token_sort_ratio(keyword, category)\n",
        "    ptsr_scores_dict[category] = fuzz.partial_token_sort_ratio(keyword, category)\n",
        "\n",
        "  tsr_score_df = pd.DataFrame(tsr_scores_dict.items(), columns=['category', 'score'])\n",
        "  ptsr_score_df = pd.DataFrame(ptsr_scores_dict.items(), columns=['category', 'score'])\n",
        "  fuzzy_score[keyword] = [tsr_score_df.sort_values('score', ascending=False).reset_index(drop=True).loc[0,'category'],\n",
        "     ptsr_score_df.sort_values('score', ascending=False).reset_index(drop=True).loc[0,'category']]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bbAQ81vFmryK"
      },
      "outputs": [],
      "source": [
        "fuzzy_score_df = pd.DataFrame(fuzzy_score.items(), columns = ['keyword', 'category_list'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WR3J7PceZ0DM"
      },
      "outputs": [],
      "source": [
        "fuzzy_score_final_df = pd.DataFrame(fuzzy_score_df.category_list.tolist(), columns = ['fuzzy_tsr_category', 'fuzzy_ptsr_category'], index=fuzzy_score_df['keyword']).reset_index()\n",
        "data_with_fuzzy = pd.merge(data_subset, fuzzy_score_final_df, on='keyword', how='inner')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CdtooTDB_jNd"
      },
      "outputs": [],
      "source": [
        "data_with_fuzzy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "llKfAV2X9ZGi"
      },
      "source": [
        "### Keyword Overlap Accuracy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cKSdQPdsdr9l"
      },
      "outputs": [],
      "source": [
        "# @title Fuzzy TSR Accuracy\n",
        "get_overlap_score(data_with_fuzzy, compare_category_col = 'fuzzy_tsr_category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0gM2tilCrnSP"
      },
      "outputs": [],
      "source": [
        "# @title Fuzzy PTSR Accuracy\n",
        "get_overlap_score(data_with_fuzzy, compare_category_col = 'fuzzy_ptsr_category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WXFsW0Ky3E2r"
      },
      "source": [
        "### Load USE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TB7x6KQe30z5"
      },
      "outputs": [],
      "source": [
        "from absl import logging\n",
        "\n",
        "import tensorflow as tf\n",
        "\n",
        "import tensorflow_hub as hub\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import re\n",
        "import seaborn as sns\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import pairwise\n",
        "\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text  # Imports TF ops for preprocessing."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ucfl3PqR30Xb"
      },
      "outputs": [],
      "source": [
        "module_url = \"https://tfhub.dev/google/universal-sentence-encoder-large/5\" #@param [\"https://tfhub.dev/google/universal-sentence-encoder/4\", \"https://tfhub.dev/google/universal-sentence-encoder-large/5\", \"https://tfhub.dev/tensorflow/bert_en_cased_L-12_H-768_A-12/4\"]\n",
        "USE_MODEL = hub.load(module_url)\n",
        "print (\"module %s loaded\" % module_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aYZjE2HXkmDC"
      },
      "outputs": [],
      "source": [
        "def use_embed(input):\n",
        "  return USE_MODEL(input)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeXTo3Uu4Bkt"
      },
      "source": [
        "### Load BERT (+ preprocessor)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BMwfFmj24DzT"
      },
      "outputs": [],
      "source": [
        "# load model for BERT\n",
        "bert_model_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\" # @param {type: \"string\"} [\"https://tfhub.dev/google/experts/bert/wiki_books/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/mnli/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/qnli/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/qqp/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/squad2/2\", \"https://tfhub.dev/google/experts/bert/wiki_books/sst2/2\",  \"https://tfhub.dev/google/experts/bert/pubmed/2\", \"https://tfhub.dev/google/experts/bert/pubmed/squad2/2\", \"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\"]\n",
        "# Preprocessing must match the model, but all the above use the same.\n",
        "bert_preprocess_url = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fGbq31u54Qsu"
      },
      "outputs": [],
      "source": [
        "BERT_PREPROCESS_MODEL = hub.load(bert_preprocess_url)\n",
        "BERT_MODEL = hub.load(bert_model_url)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fu3lEAud4w7v"
      },
      "outputs": [],
      "source": [
        "def get_bert_tensor(text_list):\n",
        "  inputs = BERT_PREPROCESS_MODEL(text_list)\n",
        "  outputs = BERT_MODEL(inputs)\n",
        "  return tf.reduce_mean(outputs['sequence_output'], axis=1) #outputs['pooled_output']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CSXoInDOb4ZB"
      },
      "outputs": [],
      "source": [
        "get_bert_tensor(['get embeddings for these words individually']).shape"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nuva-9cridmZ"
      },
      "source": [
        "### Load PALM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fRDz_daaifl0"
      },
      "outputs": [],
      "source": [
        "# load palm\n",
        "\n",
        "import numpy as np\n",
        "import google.generativeai as palm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "N5Mf6qETDg5S"
      },
      "outputs": [],
      "source": [
        "# get palm api key\n",
        "API_KEY = \"\" # @param {type: \"string\"}\n",
        "palm.configure(api_key=API_KEY)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xukg9XL7Do7l"
      },
      "outputs": [],
      "source": [
        "for model in palm.list_models():\n",
        "  if 'embedText' in model.supported_generation_methods:\n",
        "    print(model.name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8tjUZmFcihRl"
      },
      "outputs": [],
      "source": [
        "# get palm embeddings\n",
        "x = 'What do squirrels eat?'\n",
        "\n",
        "close_to_x = 'nuts and acorns'\n",
        "\n",
        "different_from_x = 'This morning I woke up in San Francisco, and took a walk to the Bay Bridge. It was a good, sunny morning with no fog.'\n",
        "\n",
        "model = \"models/embedding-gecko-001\"\n",
        "\n",
        "# Create an embedding\n",
        "\n",
        "def get_palm_tensor(text_list):\n",
        "  embeddings_series = pd.Series(text_list).apply(palm_embeddings)\n",
        "  return embeddings_series.tolist()\n",
        "\n",
        "def palm_embeddings(x):\n",
        "  model =\"models/embedding-gecko-001\"\n",
        "  return palm.generate_embeddings(model=model, text=x)['embedding']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UktizxAVia0P"
      },
      "source": [
        "### Taxonomy embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9uRTVrTuivkY"
      },
      "outputs": [],
      "source": [
        "#data_subset.category.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_aCNAu6McFmS"
      },
      "outputs": [],
      "source": [
        "tax_category_use_embeddings = dict(zip(data_subset.category.unique(), use_embed(data_subset.category.unique())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EXjgDPcOkhbR"
      },
      "outputs": [],
      "source": [
        "tax_category_bert_embeddings = dict(zip(data_subset.category.unique(), get_bert_tensor(data_subset.category.unique())))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pMT18NAak49l"
      },
      "outputs": [],
      "source": [
        "# tax_category_palm_embeddings\n",
        "tax_category_palm_embeddings = dict(zip(data_subset.category.unique(), get_palm_tensor(data_subset.category.unique())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5mdHLAVLyyIr"
      },
      "source": [
        "### Keyword embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V3cxjlYZyxQ9"
      },
      "outputs": [],
      "source": [
        "keyword_use_embeddings = dict(zip(data_subset.keyword.unique(), use_embed(data_subset.keyword.unique())))\n",
        "keyword_bert_embeddings = dict(zip(data_subset.keyword.unique(), get_bert_tensor(data_subset.keyword.unique())))\n",
        "keyword_palm_embeddings = dict(zip(data_subset.keyword.unique(), get_palm_tensor(data_subset.keyword.unique())))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l01XEGg-4y_m"
      },
      "source": [
        "### Get Closest Match"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "EdheCCX-2Ohm"
      },
      "outputs": [],
      "source": [
        "# @title Calculations\n",
        "def get_cosine_bw_embeddings(embeddings_1, embeddings_2):\n",
        "  return pairwise.cosine_similarity(embeddings_1, embeddings_2)\n",
        "\n",
        "def get_best_match(keyword_embeddings, tax_category_embeddings):\n",
        "  keyword_cosine_embedding_matches = {}\n",
        "  for keyword in keyword_embeddings.keys():\n",
        "    cosine_similarity = get_cosine_bw_embeddings(list(tax_category_embeddings.values()), [list(keyword_embeddings[keyword])])\n",
        "    best_match_category = list(tax_category_embeddings.keys())[pd.Series(list(cosine_similarity)).apply(lambda x: x[0]).idxmax()]\n",
        "    keyword_cosine_embedding_matches[keyword] = best_match_category\n",
        "  return keyword_cosine_embedding_matches\n",
        "\n",
        "keyword_cosine_use_matches = get_best_match(keyword_use_embeddings, tax_category_use_embeddings)\n",
        "keyword_cosine_bert_matches = get_best_match(keyword_bert_embeddings, tax_category_bert_embeddings)\n",
        "keyword_cosine_palm_matches = get_best_match(keyword_palm_embeddings, tax_category_palm_embeddings)\n",
        "\n",
        "bert_recommendations = pd.DataFrame(keyword_cosine_bert_matches, index=[0]).T.reset_index().rename(columns={'index': 'keyword', 0: 'bert_category'})\n",
        "use_recommendations = pd.DataFrame(keyword_cosine_use_matches, index=[0]).T.reset_index().rename(columns={'index': 'keyword', 0: 'use_category'})\n",
        "palm_recommendations = pd.DataFrame(keyword_cosine_palm_matches, index=[0]).T.reset_index().rename(columns={'index': 'keyword', 0: 'palm_category'})\n",
        "\n",
        "\n",
        "data_subset_recommendations = pd.merge(data_subset, bert_recommendations, on='keyword')\n",
        "data_subset_recommendations = pd.merge(data_subset_recommendations, use_recommendations, on='keyword')\n",
        "data_subset_recommendations = pd.merge(data_subset_recommendations, palm_recommendations, on='keyword')\n",
        "data_subset_recommendations = pd.merge(data_subset_recommendations, fuzzy_score_final_df, on='keyword')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "tB1Du57_8Uz6"
      },
      "outputs": [],
      "source": [
        "# @title Embedding Accuracy\n",
        "print(\"BERT Accuracy: \", get_overlap_score(data_subset_recommendations, 'bert_category'))\n",
        "print(\"USE Accuracy: \", get_overlap_score(data_subset_recommendations, 'use_category'))\n",
        "print(\"PaLM Accuracy: \", get_overlap_score(data_subset_recommendations, 'palm_category'))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-990mmYa0Qlw"
      },
      "source": [
        "Using a combination of fuzzy matching + embeddings"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "nZQ2hik4y7hF"
      },
      "outputs": [],
      "source": [
        "# @title Combined Accuracy\n",
        "data_subset_recommendations['fuzzy_match'] = np.where(data_subset_recommendations.fuzzy_tsr_category == data_subset_recommendations.category, 1, 0)\n",
        "data_subset_recommendations['excl_use_match'] = np.where(((data_subset_recommendations.use_category == data_subset_recommendations.category)\n",
        "\u0026 (data_subset_recommendations.fuzzy_match == 0)), 1, 0)\n",
        "data_subset_recommendations['excl_palm_match'] = np.where(((data_subset_recommendations.palm_category == data_subset_recommendations.category)\n",
        "\u0026 (data_subset_recommendations.fuzzy_match == 0)), 1, 0)\n",
        "\n",
        "print(\"Use + Fuzzy Combined Accuracy: \", ((sum(data_subset_recommendations.fuzzy_match) + sum(data_subset_recommendations.excl_use_match)) * 100)/data_subset_recommendations.shape[0])\n",
        "print(\"PaLM + Fuzzy Combined Accuracy: \",((sum(data_subset_recommendations.fuzzy_match) + sum(data_subset_recommendations.excl_palm_match)) * 100)/data_subset_recommendations.shape[0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vlE8lXy0PZYd"
      },
      "outputs": [],
      "source": [
        "category_list = list(set(data_subset_recommendations.category.to_list()))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "e-9hDehq4hHU"
      },
      "outputs": [],
      "source": [
        "# @title F1 Scores\n",
        "from sklearn import metrics\n",
        "print( \"Fuzzy TSR F1: \", metrics.f1_score(data_subset_recommendations.category.to_list(), data_subset_recommendations.fuzzy_tsr_category.to_list(), average='macro'))\n",
        "#print( \"BERT F1: \", metrics.f1_score(data_subset_recommendations.category.to_list(), data_subset_recommendations.bert_category.to_list(), average='macro'))\n",
        "print( \"USE F1: \", metrics.f1_score(data_subset_recommendations.category.to_list(), data_subset_recommendations.use_category.to_list(), average='macro'))\n",
        "print( \"PaLM F1: \", metrics.f1_score(data_subset_recommendations.category.to_list(), data_subset_recommendations.palm_category.to_list(), average='macro'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "KOxgXZShQU5h"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "# pd.merge(pd.DataFrame(zip(category_list, metrics.f1_score(data_subset_recommendations.category.to_list(), data_subset_recommendations.fuzzy_tsr_category.to_list(), average=None, labels=category_list), metrics.f1_score(data_subset_recommendations.category.to_list(), data_subset_recommendations.palm_category.to_list(), average=None, labels=category_list))),\n",
        "# pd.DataFrame(data_subset_recommendations.groupby('category').count()['palm_category']).reset_index(), left_on=0, right_on='category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tJehDYyrRTSb"
      },
      "source": [
        "Sample MisClassifications"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "_FEOXU1zRiyl"
      },
      "outputs": [],
      "source": [
        "# @title\n",
        "def get_sample_misclassifications(df, column, sample=100):\n",
        "  return df[df.category != df[column]].sample(min(df[df.category != df[column]].shape[0], sample))[['keyword', 'category', column]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "CaiJAa4u699W"
      },
      "outputs": [],
      "source": [
        "# @title Fuzzy Misclassifications\n",
        "get_sample_misclassifications(data_subset_recommendations, 'fuzzy_tsr_category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "7ecqL1foRS7D"
      },
      "outputs": [],
      "source": [
        "# @title BERT Misclassifications\n",
        "get_sample_misclassifications(data_subset_recommendations, 'bert_category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "91T5MgQFSRtg"
      },
      "outputs": [],
      "source": [
        "# @title USE Misclassifications\n",
        "get_sample_misclassifications(data_subset_recommendations, 'use_category')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "WQqFULtrSQIo"
      },
      "outputs": [],
      "source": [
        "# @title PaLM Misclassifications\n",
        "get_sample_misclassifications(data_subset_recommendations, 'palm_category')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nzFG03d9_FrY"
      },
      "source": [
        "## PCA \u0026 tSNE on Keywords"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YN5w2yCVPg8u"
      },
      "outputs": [],
      "source": [
        "from sklearn.decomposition import PCA\n",
        "from sklearn.cluster import KMeans"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z8OaG9f07TTx"
      },
      "source": [
        "#### Using USE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yGfS-IjCAQAK"
      },
      "outputs": [],
      "source": [
        "keyword_use_np_embeddings = {}\n",
        "for keyword in keyword_use_embeddings.keys():\n",
        "  keyword_use_np_embeddings[keyword] = np.array(keyword_use_embeddings[keyword])\n",
        "keyword_use_embeddings_df = pd.DataFrame(list(keyword_use_np_embeddings.values()))\n",
        "keyword_use_embeddings_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wq3elIb0BOYQ"
      },
      "outputs": [],
      "source": [
        "keyword_use_embeddings_df.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EO4pfHL7PWxo"
      },
      "outputs": [],
      "source": [
        "pca = PCA(n_components=2)\n",
        "pca_df = pd.DataFrame(pca.fit_transform(keyword_use_embeddings_df), index=keyword_use_embeddings.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sFfZ9432PrdX"
      },
      "outputs": [],
      "source": [
        "pca_df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "B1UoIOmjPswF"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "kmeans = KMeans(n_clusters=6)\n",
        "cluster_ids = kmeans.fit_predict(pca_df)\n",
        "pca_df['cluster_ids'] = cluster_ids"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5G_x7s5CP4M-"
      },
      "outputs": [],
      "source": [
        "pca_df = pca_df.reset_index()\n",
        "pca_df.columns = ['keyword', 'pca_0', 'pca_1', 'cluster_ids']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vWb1sgX3QevF"
      },
      "outputs": [],
      "source": [
        "pca_df = pd.merge(pca_df, data_subset[['keyword', 'category']], on='keyword')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wPITj8KDQHy1"
      },
      "outputs": [],
      "source": [
        "pca_df['cluster_ids'] = pca_df.cluster_ids.astype(str)\n",
        "fig = px.scatter(x='pca_0', y='pca_1', data_frame=pca_df, color='category', hover_data=['category'])\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=1000,)\n",
        "fig.layout.xaxis.color = 'black'\n",
        "fig.layout.yaxis.color = 'black'\n",
        "fig.update_yaxes(linecolor=\"black\")\n",
        "fig.update_xaxes(linecolor=\"black\")\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(256, 256, 256, 1)',\n",
        "'paper_bgcolor': 'rgba(256, 256, 256, 1)',\n",
        "})\n",
        "fig.update_traces(marker={'size': 15})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Skhjnk87aQr"
      },
      "source": [
        "#### Use PaLM"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2TbY11HYQ9Gi"
      },
      "outputs": [],
      "source": [
        "keyword_palm_embeddings_df = pd.DataFrame(list(keyword_palm_embeddings.values()))\n",
        "keyword_palm_embeddings_df.head()\n",
        "pca = PCA(n_components=2)\n",
        "pca_df = pd.DataFrame(pca.fit_transform(keyword_palm_embeddings_df), index=keyword_palm_embeddings.keys())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ViURMF8t7h8v"
      },
      "outputs": [],
      "source": [
        "import plotly.express as px\n",
        "kmeans = KMeans(n_clusters=6)\n",
        "cluster_ids = kmeans.fit_predict(pca_df)\n",
        "pca_df['cluster_ids'] = cluster_ids\n",
        "pca_df = pca_df.reset_index()\n",
        "pca_df.columns = ['keyword', 'pca_0', 'pca_1', 'cluster_ids']\n",
        "pca_df = pd.merge(pca_df, data_subset[['keyword', 'category']], on='keyword')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fmaxzId27p0T"
      },
      "outputs": [],
      "source": [
        "pca_df['cluster_ids'] = pca_df.cluster_ids.astype(str)\n",
        "fig = px.scatter(x='pca_0', y='pca_1', data_frame=pca_df, color='category', hover_data=['category', 'keyword'])\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=1000,)\n",
        "fig.layout.xaxis.color = 'black'\n",
        "fig.layout.yaxis.color = 'black'\n",
        "fig.update_yaxes(linecolor=\"black\")\n",
        "fig.update_xaxes(linecolor=\"black\")\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(256, 256, 256, 1)',\n",
        "'paper_bgcolor': 'rgba(256, 256, 256, 1)',\n",
        "})\n",
        "fig.update_traces(marker={'size': 15})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bMTS3uPn8rT1"
      },
      "outputs": [],
      "source": [
        "#tSNE plot\n",
        "\n",
        "import pandas as pd\n",
        "from sklearn.manifold import TSNE\n",
        "import numpy as np\n",
        "from ast import literal_eval\n",
        "\n",
        "# Convert to a list of lists of floats\n",
        "matrix = np.array(list(keyword_palm_embeddings.values()))\n",
        "\n",
        "# Create a t-SNE model and transform the data\n",
        "tsne = TSNE(n_components=2, perplexity=15, random_state=42, init='random', learning_rate=200)\n",
        "vis_dims = tsne.fit_transform(matrix)\n",
        "vis_dims.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "MM9wNGVk9bwN"
      },
      "outputs": [],
      "source": [
        "tsne_df = pd.DataFrame(vis_dims, index=keyword_palm_embeddings.keys()).reset_index()\n",
        "tsne_df.columns = ['keyword', 'x', 'y']\n",
        "tsne_df = pd.merge(tsne_df, data_subset[['keyword', 'category']], on='keyword')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oIQz89hI_L1p"
      },
      "outputs": [],
      "source": [
        "#pca_df['cluster_ids'] = pca_df.cluster_ids.astype(str)\n",
        "fig = px.scatter(x='x', y='y', data_frame=tsne_df, color='category', hover_data=['keyword']) #level1\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=1000,)\n",
        "fig.layout.xaxis.color = 'black'\n",
        "fig.layout.yaxis.color = 'black'\n",
        "fig.update_yaxes(linecolor=\"black\")\n",
        "fig.update_xaxes(linecolor=\"black\")\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(256, 256, 256, 1)',\n",
        "'paper_bgcolor': 'rgba(256, 256, 256, 1)',\n",
        "})\n",
        "fig.update_traces(marker={'size': 15})"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ScYjQM2t-AcB"
      },
      "outputs": [],
      "source": [
        "#pca_df['cluster_ids'] = pca_df.cluster_ids.astype(str)\n",
        "fig = px.scatter(x='x', y='y', data_frame=tsne_df, color='category', hover_data=['keyword'])\n",
        "fig.update_layout(\n",
        "    autosize=False,\n",
        "    width=1600,\n",
        "    height=1000,)\n",
        "fig.layout.xaxis.color = 'black'\n",
        "fig.layout.yaxis.color = 'black'\n",
        "fig.update_yaxes(linecolor=\"black\")\n",
        "fig.update_xaxes(linecolor=\"black\")\n",
        "fig.update_layout({\n",
        "'plot_bgcolor': 'rgba(256, 256, 256, 1)',\n",
        "'paper_bgcolor': 'rgba(256, 256, 256, 1)',\n",
        "})\n",
        "fig.update_traces(marker={'size': 15})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "J3A7W4JZGtug"
      },
      "source": [
        "## Keyword Matching Demo (User Input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "TMI2oXpBKnfY"
      },
      "outputs": [],
      "source": [
        "# @title Available Taxonomy Categories\n",
        "data_subset.category.unique()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "cellView": "form",
        "id": "sfl5xI_nG3ep"
      },
      "outputs": [],
      "source": [
        "# @title ad-hoc classification\n",
        "adhoc_keywords = 'ppt' #@param\n",
        "adhoc_keywords = adhoc_keywords.split(\",\")\n",
        "adhoc_keywords = [keyword.strip() for keyword in adhoc_keywords]\n",
        "ex_keywords = pd.DataFrame(adhoc_keywords, columns=['keyword'])\n",
        "\n",
        "# get embeddings for given keywords\n",
        "ex_keyword_use_embeddings = dict(zip(ex_keywords.keyword.unique(), use_embed(ex_keywords.keyword.unique())))\n",
        "ex_keyword_bert_embeddings = dict(zip(ex_keywords.keyword.unique(), get_bert_tensor(ex_keywords.keyword.unique())))\n",
        "ex_keyword_palm_embeddings = dict(zip(ex_keywords.keyword.unique(), get_palm_tensor(ex_keywords.keyword.unique())))\n",
        "\n",
        "# get matches\n",
        "ex_keyword_cosine_use_matches = get_best_match(ex_keyword_use_embeddings, tax_category_use_embeddings)\n",
        "ex_keyword_cosine_bert_matches = get_best_match(ex_keyword_bert_embeddings, tax_category_bert_embeddings)\n",
        "ex_keyword_cosine_palm_matches = get_best_match(ex_keyword_palm_embeddings, tax_category_palm_embeddings)\n",
        "\n",
        "# get recommendations\n",
        "ex_bert_recommendations = pd.DataFrame(ex_keyword_cosine_bert_matches, index=[0]).T.reset_index().rename(columns={'index': 'keyword', 0: 'bert_category'})\n",
        "ex_use_recommendations = pd.DataFrame(ex_keyword_cosine_use_matches, index=[0]).T.reset_index().rename(columns={'index': 'keyword', 0: 'use_category'})\n",
        "ex_palm_recommendations = pd.DataFrame(ex_keyword_cosine_palm_matches, index=[0]).T.reset_index().rename(columns={'index': 'keyword', 0: 'palm_category'})\n",
        "\n",
        "# get keyword fuzzy recommendations\n",
        "ex_tsr_scores_dict = {}\n",
        "ex_ptsr_scores_dict = {}\n",
        "ex_fuzzy_score = {}\n",
        "\n",
        "for i, keyword in enumerate((adhoc_keywords)):\n",
        "  for j, category in enumerate(category_list):\n",
        "    ex_tsr_scores_dict[category] = fuzz.token_sort_ratio(keyword, category)\n",
        "    ex_ptsr_scores_dict[category] = fuzz.partial_token_sort_ratio(keyword, category)\n",
        "\n",
        "  ex_tsr_score_df = pd.DataFrame(ex_tsr_scores_dict.items(), columns=['category', 'score'])\n",
        "  ex_ptsr_score_df = pd.DataFrame(ex_ptsr_scores_dict.items(), columns=['category', 'score'])\n",
        "  ex_fuzzy_score[keyword] = [ex_tsr_score_df.sort_values('score', ascending=False).reset_index(drop=True).loc[0,'category'],\n",
        "     ex_ptsr_score_df.sort_values('score', ascending=False).reset_index(drop=True).loc[0,'category']]\n",
        "\n",
        "ex_fuzzy_score_df = pd.DataFrame(ex_fuzzy_score.items(), columns = ['keyword', 'category_list'])\n",
        "ex_fuzzy_score_final_df = pd.DataFrame(ex_fuzzy_score_df.category_list.tolist(), columns = ['fuzzy_tsr_category', 'fuzzy_ptsr_category'], index=ex_fuzzy_score_df['keyword']).reset_index()\n",
        "\n",
        "# get outputs\n",
        "print(\"Output from fuzzy matching algorithms:\")\n",
        "display(ex_fuzzy_score_final_df)\n",
        "print(\"Outputs from different embedding models:\")\n",
        "print(\"BERT: \")\n",
        "display(ex_bert_recommendations)\n",
        "print(\"USE: \")\n",
        "display(ex_use_recommendations)\n",
        "print(\"PALM: \")\n",
        "display(ex_palm_recommendations)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1hag5CFERS6y"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "UktizxAVia0P"
      ],
      "last_runtime": {
        "build_target": "//corp/gtech/ads/infrastructure/colab_utils/ds_runtime:ds_colab",
        "kind": "private"
      },
      "private_outputs": true,
      "provenance": [
        {
          "file_id": "1V5_O10rV-FOl62kHjXgJAcjeZGt9X2NQ",
          "timestamp": 1701659528530
        }
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
